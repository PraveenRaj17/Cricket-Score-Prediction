{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "matches_data = pd.read_csv('matches.csv')\n",
    "deliveries_data = pd.read_csv('deliveries.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalrun_df = deliveries_data.groupby(['match_id','inning']).sum()['total_runs'].reset_index()\n",
    "\n",
    "totalrun_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalrun_df = totalrun_df[totalrun_df['inning']==1]\n",
    "totalrun_df['target_set'] = totalrun_df['total_runs'].apply(lambda x:x+1)\n",
    "totalrun_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing old team names with new ones\n",
    "teams_mapping = {\n",
    "    'Delhi Daredevils': 'Delhi Capitals',\n",
    "    'Deccan Chargers': 'Sunrisers Hyderabad'\n",
    "}\n",
    "matches_data.replace({'team1': teams_mapping, 'team2': teams_mapping}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering frequently occurring teams\n",
    "# Excluding teams like Kochi Tuskers, Pune Warriors, etc.\n",
    "frequent_teams = [\n",
    "    'Sunrisers Hyderabad', 'Mumbai Indians', 'Royal Challengers Bangalore',\n",
    "    'Kolkata Knight Riders', 'Kings XI Punjab', 'Chennai Super Kings',\n",
    "    'Rajasthan Royals', 'Delhi Capitals'\n",
    "]\n",
    "filtered_matches_data = matches_data[matches_data['team1'].isin(frequent_teams) & matches_data['team2'].isin(frequent_teams)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling DL method and filtering columns\n",
    "# We reject matches involving DL method just to avoid confusing our model\n",
    "matches_without_dl = filtered_matches_data[filtered_matches_data['dl_applied'] == 0]\n",
    "matches_without_dl = matches_without_dl[['id', 'city', 'winner']]\n",
    "matches_without_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_without_dl = matches_without_dl.merge(totalrun_df[['match_id', 'target_set']],\n",
    "                       left_on='id',right_on='match_id')\n",
    "\n",
    "matches_without_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging match data with deliveries data\n",
    "merged_data = matches_without_dl.merge(deliveries_data, left_on='id', right_on='match_id')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_data['total_runs_inn1'] = merged_data.groupby(['match_id', 'inning']).sum()['total_runs'].reset_index()['total_runs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering second innings data\n",
    "second_innings_data = merged_data[merged_data['inning'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_innings_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling nan values with \"0\"\n",
    "\n",
    "second_innings_data['player_dismissed'] = second_innings_data['player_dismissed'].fillna(\"0\")\n",
    "\n",
    "# now we will convert this player_dismissed col into a boolean col\n",
    "# if the player is not dismissed then it's 0 else it's 1\n",
    "\n",
    "second_innings_data['player_dismissed'] = second_innings_data['player_dismissed'].apply(lambda x:x\n",
    "                                                                      if x==\"0\" else \"1\")\n",
    "\n",
    "# converting string to int\n",
    "\n",
    "second_innings_data['player_dismissed'] = second_innings_data['player_dismissed'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_innings_data['player_dismissed'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating current score, runs left, balls left, wickets left, current run rate, and required run rate\n",
    "second_innings_data['current_score'] = second_innings_data.groupby('match_id_y')['total_runs'].cumsum()\n",
    "second_innings_data['runs_left'] = second_innings_data['target_set'] - second_innings_data['current_score']\n",
    "second_innings_data['balls_left'] = 126 - (second_innings_data['over'] * 6 + second_innings_data['ball'])\n",
    "second_innings_data['wickets_left'] = 10 - second_innings_data.groupby('match_id_y')['player_dismissed'].cumsum()\n",
    "second_innings_data['cur_run_rate'] = (second_innings_data['current_score'] * 6) / (120 - second_innings_data['balls_left'])\n",
    "second_innings_data['req_run_rate'] = (second_innings_data['runs_left'] * 6) / second_innings_data['balls_left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_innings_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating result column indicating win/lose\n",
    "second_innings_data.loc[:, 'result'] = second_innings_data['batting_team'] == second_innings_data['winner']\n",
    "second_innings_data.loc[:, 'result'] = second_innings_data['result'].astype(int)\n",
    "second_innings_data['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final DataFrame with features for modeling\n",
    "final_data = second_innings_data[['batting_team', 'bowling_team', 'city', 'runs_left',\n",
    "                                  'balls_left', 'wickets_left', 'target_set', 'cur_run_rate',\n",
    "                                  'req_run_rate', 'result']]\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping null values\n",
    "final_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out rows where balls_left = 0\n",
    "final_data = final_data[final_data['balls_left'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test sets\n",
    "X = final_data.drop('result', axis=1)\n",
    "y = final_data['result']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining categorical columns for one-hot encoding\n",
    "categorical_columns = ['batting_team', 'bowling_team', 'city']\n",
    "# Defining ColumnTransformer\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[('encoder', OneHotEncoder(drop='first'), categorical_columns)],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Logistic Regression Pipeline\n",
    "logistic_pipeline = Pipeline([\n",
    "    ('preprocessor', column_transformer),\n",
    "    ('classifier', LogisticRegression(solver='liblinear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Logistic Regression model\n",
    "logistic_pipeline.fit(X_train, y_train)\n",
    "logistic_accuracy = logistic_pipeline.score(X_test, y_test)\n",
    "print(\"Logistic Regression Accuracy:\", logistic_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Logistic Regression model\n",
    "pickle.dump(logistic_pipeline, open('logistic_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Random Forest Pipeline\n",
    "random_forest_pipeline = Pipeline([\n",
    "    ('preprocessor', column_transformer),\n",
    "    ('classifier', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting Random Forest model\n",
    "random_forest_pipeline.fit(X_train, y_train)\n",
    "random_forest_accuracy = random_forest_pipeline.score(X_test, y_test)\n",
    "print(\"Random Forest Accuracy:\", random_forest_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving Random Forest model\n",
    "pickle.dump(random_forest_pipeline, open('random_forest_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
